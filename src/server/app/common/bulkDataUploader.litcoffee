
# bulkDataUploader module

This module is responsible for all bulk data upload operations of collected user data (that is all the documents that were generated by the user either on MOFS or on other sources).

Bulk-uploading accomplishes two things:

1. Uploading data in bulk is much faster.
2. Uploading data in bulk is much cheaper (in actual money) when using DaaS service like Cloudant (which treats bulk requests as a single request)

Uploading is triggered when an arbitrary number of documents is reached (10,000 right now) *or* if more than an arbitrary number of seconds (60 right now) has passed since that last upload and there are documents to be uploaded.

## Initialization

    _       = require 'lodash'
    debug   = (require 'debug') 'memdive::common::bulkDataUploader'
    frugal  = require 'frugal-couch'

    app = undefined

    testEnvironment = process.env.NODE_ENV == 'test'

The module is integrated into CompoundJS application.

    module.exports.init = (compound) ->
        compound.on 'ready', (compoundApp) ->
            app = compoundApp

            app.common = app.common or {}
            app.common.bulkDataUploader = exports
            app.emit 'bulkDataUploaderReady'

When running in test environment doing time-based forced uploads kills the deterministic nature and makes tests much harder to perform. All tests anyway force the doc upload by invoking `flush` directly.

            if not testEnvironment
                # Schedule the first trigger which will then schedule other triggers.
                setTimeout scheduledBulkUpload, UPLOAD_THRESHOLD_DELAY

## Constants

    UPLOAD_THRESHOLD_COUNT = 10000
    UPLOAD_THRESHOLD_DELAY = 5 * 1000
    UPLOAD_RETRY_COUNT = 5

## Private data

    enqueuedDocs = []
    lastUploadTimestamp = new Date().getTime()

## Private functions

`tryUploadDocs` will try to bulk-upload the given docs until UPLOAD_RETRY_COUNT is reached. Between each attempt there will be UPLOAD_THRESHOLD_DELAY delay.

    tryUploadDocs = (callback, docs, retryCount) ->
        console.log 'count#overwrite-bulk=1'
        console.log 'count#overwrite-bulk-docs=' + docs.length
        frugal.overwriteBulk app.couch, docs, (err) ->
            if not err
                debug 'Uploaded', docs.length, 'docs.'
                return callback null, docs.length

            debug 'Failed to upload', docs.length, 'docs:', err
            console.log 'count#overwrite-bulk-failed=1'
            if retryCount < UPLOAD_RETRY_COUNT
                return setTimeout ->
                    tryUploadDocs docs, retryCount + 1 or 1
                , UPLOAD_THRESHOLD_DELAY

            debug 'Quitting uploading after', retryCount, 'tries'
            callback err

    uploadEnquedDocs = (callback, async) ->

        lastUploadTimestamp = new Date().getTime()

        callback = callback or () -> {}

        return callback(null, 0) if _.isEmpty enqueuedDocs

        debug 'uploadEnquedDocs', enqueuedDocs.length, new Date(lastUploadTimestamp)

        docsToUpload = enqueuedDocs
        enqueuedDocs = []

        if async
            return setTimeout ->
                tryUploadDocs callback, docsToUpload
            , 0

        tryUploadDocs callback, docsToUpload

    uploadEnquedDocsAsyc = (callback) ->
        uploadEnquedDocs callback, true

    uploadTimeThresholdReached = ->
        (lastUploadTimestamp + UPLOAD_THRESHOLD_DELAY) <= new Date().getTime()

    scheduledBulkUpload = ->
        # Reschedule thyself.
        setTimeout scheduledBulkUpload, UPLOAD_THRESHOLD_DELAY
        triggerUploadIfNeeded()

`triggerUploadIfNeeded` will upload the given docs on the next idle opportunity.

    triggerUploadIfNeeded = ->
        if enqueuedDocs.length >= UPLOAD_THRESHOLD_COUNT or (not testEnvironment and uploadTimeThresholdReached())
            uploadEnquedDocsAsyc()

## Public functions

### `enqueue`

`enqueue` function enqueues the given doc for the next bulk upload to the database.

It takes the following parameters:

* `docs`:  the doc to upload *or* an array of docs to upload

--

    enqueue = (docs) ->

        if _.isArray docs
            enqueuedDocs = enqueuedDocs.concat(docs)
            console.log 'count#enqueued-docs=' + docs.length
        else
            enqueuedDocs.push docs
            console.log 'count#enqueued-docs=' + 1

        triggerUploadIfNeeded()

    exports.enqueue = enqueue

### `flush`

`flush` forces the upload of all currently enqueued documents.

It takes the following parameters:

* `callback`:  an optional callback function to invoke when the data has been uploaded to the database

--

    exports.flush = (callback, async) ->
        console.log 'count#flush-docs=1'
        uploadEnquedDocs(callback, async)
